{"version":3,"sources":["entry.module.css","Entry.js","App.js","serviceWorker.js","index.js"],"names":["module","exports","Entry","props","className","style","entry","href","data","link","title","authors","published","summary","App","useState","entries","setEntries","topicInput","setTopicInput","limitInput","setLimitInput","startDateInput","setStartDateInput","endDateInput","setEndDateInput","showResults","setShowResults","topic","limit","startDate","endDate","query","setQuery","useEffect","scrapeArXiv","sleep","ms","Promise","resolve","setTimeout","a","start","fetch","response","text","responseString","results","Array","prototype","slice","call","window","DOMParser","parseFromString","querySelectorAll","length","trim","Date","getTime","publishDateString","querySelector","textContent","publishDate","previousResults","console","log","toDateString","retries","concat","reverse","filtered","i","push","parseData","metadata","replace","rawDate","names","j","join","getAttribute","Helmet","onSubmit","e","preventDefault","alert","isNaN","parseInt","isValidInput","Math","min","type","placeholder","value","onChange","target","filename","size","color","map","key","Boolean","location","hostname","match","ReactDOM","render","StrictMode","document","getElementById","navigator","serviceWorker","ready","then","registration","unregister","catch","error","message"],"mappings":"sFACAA,EAAOC,QAAU,CAAC,MAAQ,uB,0OCeXC,EAbD,SAACC,GACX,OACI,yBAAKC,UAAWC,IAAMC,OAClB,gCAAK,uBAAGC,KAAMJ,EAAMK,KAAKC,MAApB,IAA4BN,EAAMK,KAAKE,OAA5C,KACA,2BAAIP,EAAMK,KAAKG,SACf,wCAAcR,EAAMK,KAAKI,WACzB,2BAAIT,EAAMK,KAAKK,SACf,8BC4PGC,G,MA/PH,WAAM,MAGcC,mBAAS,IAHvB,mBAGTC,EAHS,KAGAC,EAHA,OAIoBF,mBAAS,IAJ7B,mBAITG,EAJS,KAIGC,EAJH,OAKoBJ,mBAAS,IAL7B,mBAKTK,EALS,KAKGC,EALH,OAM4BN,mBAAS,IANrC,mBAMTO,EANS,KAMOC,EANP,OAOwBR,mBAAS,IAPjC,mBAOTS,EAPS,KAOKC,EAPL,OAQsBV,oBAAS,GAR/B,mBAQTW,EARS,KAQIC,EARJ,OAgBUZ,mBAAS,CACjCa,MAAO,mBACPC,MAAO,KACPC,UAAWR,EACXS,QAASP,IApBK,mBAgBTQ,EAhBS,KAgBFC,EAhBE,KAuBhBC,qBAAU,WACRC,MACC,CAACH,IAEJ,IAAMI,EAAQ,SAACC,GACb,OAAO,IAAIC,SAAQ,SAAAC,GAAO,OAAIC,WAAWD,EAASF,OAK9CF,EAAW,uCAAG,kDAAAM,EAAA,6DAEdC,EAAQ,EAFM,SAGGC,MAAM,uDAAD,OAAwDX,EAAMJ,MAA9D,6DAAwHc,EAAxH,wBAA6IV,EAAMH,QAH3J,cAGde,EAHc,gBAISA,EAASC,OAJlB,UAIdC,EAJc,UAOdC,EAAUC,MAAMC,UAAUC,MAAMC,MAAM,IAAIC,OAAOC,WAAaC,gBAAgBR,EAAgB,YAAYS,iBAAiB,WAGnHC,OAAS,GAAKxB,EAAMF,UAAU2B,QAAUzB,EAAMD,QAAQ0B,QAVhD,iBAYZ3B,EAAY,IAAI4B,KAAK1B,EAAMF,UAAU2B,QAAQE,UAC7C5B,EAAU,IAAI2B,KAAK1B,EAAMD,QAAQ0B,QAAQE,UACzCC,EAAoBb,EAAQA,EAAQS,OAAS,GAAGK,cAAc,aAAaC,YAAYL,OACvFM,EAAc,IAAIL,KAAKE,GAAmBD,UAC1CK,EAAkB,GAhBN,aAmBTjB,EAAQS,OAAS,GAAKO,EAAcjC,GAnB3B,wBAqBdmC,QAAQC,IAAI,iBAAmB,IAAIR,KAAKE,GAAmBO,gBAG3DzB,GAAgBK,EAAQS,OACxBQ,EAAkBjB,EAzBJ,UA0BGJ,MAAM,uDAAD,OAAwDX,EAAMJ,MAA9D,6DAAwHc,EAAxH,wBA/CV,MAqBE,eA0BdE,EA1Bc,iBA2BSA,EAASC,OA3BlB,QA2BdC,EA3Bc,OA4BdC,EAAUC,MAAMC,UAAUC,MAAMC,MAAM,IAAIC,OAAOC,WAAaC,gBAAgBR,EAAgB,YAAYS,iBAAiB,UAIvHa,EAAU,EAhCA,aAiCPA,EAAU,GAAuB,GAAlBrB,EAAQS,QAjChB,wBAkCZS,QAAQC,IAAI,yCAA2CE,EAAU,GAAK,UAlC1D,UAmCKzB,MAAM,uDAAD,OAAwDX,EAAMJ,MAA9D,6DAAwHc,EAAxH,wBAxDZ,MAqBE,eAmCZE,EAnCY,iBAoCWA,EAASC,OApCpB,eAoCZC,EApCY,OAqCZC,EAAUC,MAAMC,UAAUC,MAAMC,MAAM,IAAIC,OAAOC,WAAaC,gBAAgBR,EAAgB,YAAYS,iBAAiB,UAE3Ha,GAAW,EAvCC,UAwCNhC,EAAM,KAxCA,uCA2CVW,EAAQS,OAAS,IACnBI,EAAoBb,EAAQA,EAAQS,OAAS,GAAGK,cAAc,aAAaC,YAAYL,OACvFM,EAAc,IAAIL,KAAKE,GAAmBD,WA7C9B,UAiDRvB,EAAM,KAjDE,gCA0DhB,IALAW,GADAA,EAAUiB,EAAgBK,OAAOtB,IACfuB,UACdC,EAAW,GACXC,EAAI,EAGDA,EAAIzB,EAAQS,QAAUO,GAAehC,GAC1C6B,EAAoBb,EAAQyB,GAAGX,cAAc,aAAaC,YAAYL,QACtEM,EAAc,IAAIL,KAAKE,GAAmBD,YAEvB7B,GAAayC,EAASf,OAASxB,EAAMH,OACtD0C,EAASE,KAAK1B,EAAQyB,IAExBA,GAAK,EAEPzB,EAAUwB,EAnEM,QAqElBG,EAAU3B,GArEQ,4CAAH,qDAyEX2B,EAAY,SAAC3B,GAGjB,IADA,IAAIvC,EAAO,GACFgE,EAAI,EAAGA,EAAIzB,EAAQS,OAAQgB,IAAK,CACvC,IAAIG,EAAW,GAEfA,EAAQ,MAAY5B,EAAQyB,GAAGX,cAAc,SAASC,YAAYL,OAAOmB,QAAQ,KAAM,KACvF,IAAMC,EAAU9B,EAAQyB,GAAGX,cAAc,aAAaC,YAAYL,OAAOmB,QAAQ,KAAM,KACvFD,EAAQ,UAAgB,IAAIjB,KAAKmB,GAASV,eAI1C,IAFA,IAAMxD,EAAUoC,EAAQyB,GAAGjB,iBAAiB,UACxCuB,EAAQ,GACHC,EAAI,EAAGA,EAAIpE,EAAQ6C,OAAQuB,IAClCD,EAAML,KAAK9D,EAAQoE,GAAGjB,YAAYL,QAGpCkB,EAAQ,QAAcG,EAAME,KAAK,MAAMJ,QAAQ,KAAM,KACrDD,EAAQ,QAAc5B,EAAQyB,GAAGX,cAAc,WAAWC,YAAYL,OAAOmB,QAAQ,KAAM,KAC3FD,EAAQ,KAAW5B,EAAQyB,GAAGjB,iBAAiB,QAAQ,GAAG0B,aAAa,QAAQxB,OAAOmB,QAAQ,KAAM,KACpGpE,EAAKiE,KAAKE,GAGZV,QAAQC,IAAI,WAAa1D,EAAKgD,OAAS,YACvCvC,EAAWT,GACXmB,GAAe,IA0EjB,OACE,yBAAKvB,UAAU,OACb,kBAAC8E,EAAA,EAAD,KACE,+BAAQ,YAGV,4BAAQ9E,UAAU,cAChB,wBAAIA,UAAU,aAAd,YAGF,0BAAM+E,SAxBS,SAAAC,GACjBA,EAAEC,iBAlCiB,WACnB,IAAKnE,EAAWuC,OAEd,OADA6B,MAAM,yBACC,EAGT,IAAKlE,EAAWqC,QAAU8B,MAAMnE,EAAWqC,SAAW+B,SAASpE,EAAWqC,OAAQ,KAAO,EAEvF,OADA6B,MAAM,oEACC,EAGT,GAAIhE,EAAemC,QAAUjC,EAAaiC,OAAQ,CAChD,IAAKjC,EAAaiC,OAEhB,OADA6B,MAAM,mCACC,EACF,IAAKhE,EAAemC,OAEzB,OADA6B,MAAM,oCACC,EACF,GAAuC,gBAAnC,IAAI5B,KAAKpC,EAAemC,QAEjC,OADA6B,MAAM,oDACC,EACF,GAAqC,gBAAjC,IAAI5B,KAAKlC,EAAaiC,QAE/B,OADA6B,MAAM,kDACC,EACF,GAAI,IAAI5B,KAAKpC,EAAemC,QAAQE,WAAa,IAAID,KAAKlC,EAAaiC,QAAQE,UAEpF,OADA2B,MAAM,sEACC,EAIX,OAAO,EAKHG,KACF9D,GAAe,GACfM,EAAS,CACPL,MAAOV,EAAWuC,OAClB5B,MAAO6D,KAAKC,IAvLO,IAuLeH,SAASpE,EAAWqC,OAAQ,KAC9D3B,UAAWR,EAAemC,OAC1B1B,QAASP,EAAaiC,UA/C1BtC,EAAc,IACdE,EAAc,IACdE,EAAkB,IAClBE,EAAgB,KA4DcrB,UAAU,cACpC,2BAAOA,UAAU,mBAAmBwF,KAAK,OAAOC,YAAY,sCAC1DC,MAAO5E,EAAY6E,SAlFP,SAAAX,GAClBjE,EAAciE,EAAEY,OAAOF,UAkFnB,2BAAO1F,UAAU,kBAAkBwF,KAAK,OAAOC,YAAa,0BAC1DC,MAAO1E,EAAY2E,SAhFP,SAAAX,GAClB/D,EAAc+D,EAAEY,OAAOF,UAgFnB,2BAAO1F,UAAU,iBAAiBwF,KAAK,OAAOC,YAAY,kCACxDC,MAAOxE,EAAgByE,SA9EP,SAAAX,GACtB7D,EAAkB6D,EAAEY,OAAOF,UA8EvB,2BAAO1F,UAAU,iBAAiBwF,KAAK,OAAOC,YAAY,gCACxDC,MAAOtE,EAAcuE,SA5EP,SAAAX,GACpB3D,EAAgB2D,EAAEY,OAAOF,UA4ErB,4BAAQ1F,UAAU,gBAAgBwF,KAAK,UAAvC,iBAMF,yBAAKxF,UAAU,WACZsB,EACC,yBAAKrB,MAAO,CAAE,UAAa,WACzB,gDAAsB2B,EAAMJ,MAA5B,KACA,2BAAG,kBAAC,UAAD,CAASpB,KAAMQ,EAASiF,SAAS,iBAAiBD,OAAO,UAAzD,mBAAH,YAAwGhF,EAAQwC,OAAhH,cAGF,yBAAKnD,MAAO,CAAE,UAAa,WACzB,uDACA,8GACA,yHACA,6BACA,kBAAC,aAAD,CAAY6F,KAAM,IAAKC,MAAO,YAC9B,8BAIHzE,EAAcV,EAAQkC,MAAM,EAAGwC,KAAKC,IA3OnB,GA2OwC3E,EAAQwC,SAAS4C,KAAI,SAAC5F,EAAMgE,GAAP,OAC7E,kBAAC,EAAD,CAAO6B,IAAK7B,EAAGhE,KAAMA,OAClB,SCnPO8F,QACW,cAA7BlD,OAAOmD,SAASC,UAEe,UAA7BpD,OAAOmD,SAASC,UAEhBpD,OAAOmD,SAASC,SAASC,MACvB,2DCZNC,IAASC,OACP,kBAAC,IAAMC,WAAP,KACE,kBAAC,EAAD,OAEFC,SAASC,eAAe,SDyHpB,kBAAmBC,WACrBA,UAAUC,cAAcC,MACrBC,MAAK,SAAAC,GACJA,EAAaC,gBAEdC,OAAM,SAAAC,GACLrD,QAAQqD,MAAMA,EAAMC,c","file":"static/js/main.5e469926.chunk.js","sourcesContent":["// extracted by mini-css-extract-plugin\nmodule.exports = {\"entry\":\"entry_entry__1jr6A\"};","import React from 'react';\nimport style from './entry.module.css';\n\nconst Entry = (props) => {\n    return (\n        <div className={style.entry}>\n            <h2> <a href={props.data.link}> {props.data.title}</a> </h2>\n            <p>{props.data.authors}</p>\n            <p>Published {props.data.published}</p>\n            <p>{props.data.summary}</p>\n            <p></p>\n        </div>\n    )\n}\n\n\nexport default Entry;","import React, { useEffect, useState } from 'react';\nimport { ClipLoader } from 'react-spinners';\nimport { Helmet } from 'react-helmet';\nimport { CSVLink } from 'react-csv';\nimport Entry from './Entry.js';\nimport './App.css';\n\nconst App = () => {\n\n  // Manage state variables via React Hooks\n  const [entries, setEntries] = useState([]);\n  const [topicInput, setTopicInput] = useState('');\n  const [limitInput, setLimitInput] = useState('');\n  const [startDateInput, setStartDateInput] = useState('');\n  const [endDateInput, setEndDateInput] = useState('');\n  const [showResults, setShowResults] = useState(false);\n\n  // Constants\n  const MAX_TOP_MATCHES = 20;\n  const STEP_SIZE = 500;\n  const MAX_RESULT_LIMIT = 1000;\n\n  // Default Setting\n  const [query, setQuery] = useState({\n    topic: 'Machine Learning',\n    limit: '10',\n    startDate: startDateInput,\n    endDate: endDateInput\n  });\n\n  useEffect(() => {\n    scrapeArXiv();\n  }, [query]);\n\n  const sleep = (ms) => {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n\n\n  // Use the arXiv HTTP API to scrape records based on query parameters\n  const scrapeArXiv = async () => {\n\n    var start = 0;\n    var response = await fetch(`http://export.arxiv.org/api/query?search_query=all:\"${query.topic}\"&sortBy=submittedDate&sortOrder=descending&start=${start}&max_results=${query.limit}`);\n    var responseString = await response.text();\n\n    // Parse the entries from the XML response as DOM elements and store them in a results array\n    var results = Array.prototype.slice.call((new window.DOMParser()).parseFromString(responseString, \"text/xml\").querySelectorAll('entry'));\n\n    // Continue scraping past records if a date range is specified\n    if (results.length > 0 && query.startDate.trim() && query.endDate.trim()) {\n\n      var startDate = new Date(query.startDate.trim()).getTime();\n      var endDate = new Date(query.endDate.trim()).getTime();\n      var publishDateString = results[results.length - 1].querySelector('published').textContent.trim();\n      var publishDate = new Date(publishDateString).getTime();\n      var previousResults = [];\n\n      // Paginate through sets of old records until the earliest date in the record set falls within the date range\n      while (results.length > 0 && publishDate > startDate) {\n\n        console.log(\"Scraping from \" + new Date(publishDateString).toDateString());\n\n        // Start index used for pagination \n        start = start + results.length;\n        previousResults = results;\n        response = await fetch(`http://export.arxiv.org/api/query?search_query=all:\"${query.topic}\"&sortBy=submittedDate&sortOrder=descending&start=${start}&max_results=${STEP_SIZE}`);\n        responseString = await response.text();\n        results = Array.prototype.slice.call((new window.DOMParser()).parseFromString(responseString, \"text/xml\").querySelectorAll('entry'));\n\n\n        // Retry API request up to 5 times if no data is returned\n        var retries = 0;\n        while (retries < 5 && results.length == 0) {\n          console.log('Request failed, retrying API request ' + (retries + 1) + ' times');\n          response = await fetch(`http://export.arxiv.org/api/query?search_query=all:\"${query.topic}\"&sortBy=submittedDate&sortOrder=descending&start=${start}&max_results=${STEP_SIZE}`);\n          responseString = await response.text();\n          results = Array.prototype.slice.call((new window.DOMParser()).parseFromString(responseString, \"text/xml\").querySelectorAll('entry'));\n\n          retries += 1;\n          await sleep(5000);\n        }\n\n        if (results.length > 0) {\n          publishDateString = results[results.length - 1].querySelector('published').textContent.trim();\n          publishDate = new Date(publishDateString).getTime();\n        }\n\n        // Sleep for 2 seconds to limit amount of queries\n        await sleep(2000);\n      }\n\n      results = previousResults.concat(results);\n      results = results.reverse();\n      var filtered = [];\n      var i = 0;\n\n      // Filter the results to match the given date range\n      while (i < results.length && publishDate <= endDate) {\n        publishDateString = results[i].querySelector('published').textContent.trim();\n        publishDate = new Date(publishDateString).getTime();\n\n        if (publishDate >= startDate && filtered.length < query.limit) {\n          filtered.push(results[i]);\n        }\n        i += 1;\n      }\n      results = filtered;\n    }\n    parseData(results);\n  }\n\n  // Take the DOM results array and parse the data for each relevant field\n  const parseData = (results) => {\n\n    var data = []\n    for (var i = 0; i < results.length; i++) {\n      var metadata = {}\n\n      metadata['title'] = results[i].querySelector('title').textContent.trim().replace(/\"/g, '\\'');\n      const rawDate = results[i].querySelector('published').textContent.trim().replace(/\"/g, '\\'');;\n      metadata['published'] = new Date(rawDate).toDateString();\n\n      const authors = results[i].querySelectorAll('author');\n      var names = [];\n      for (var j = 0; j < authors.length; j++) {\n        names.push(authors[j].textContent.trim());\n      }\n\n      metadata['authors'] = names.join(', ').replace(/\"/g, '\\'');\n      metadata['summary'] = results[i].querySelector('summary').textContent.trim().replace(/\"/g, '\\'');\n      metadata['link'] = results[i].querySelectorAll('link')[1].getAttribute('href').trim().replace(/\"/g, '\\'');\n      data.push(metadata);\n    }\n\n    console.log('Scraped ' + data.length + ' entries');\n    setEntries(data);\n    setShowResults(true);\n  }\n\n\n  const updateTopic = e => {\n    setTopicInput(e.target.value);\n  }\n\n  const updateLimit = e => {\n    setLimitInput(e.target.value);\n  }\n\n  const updateStartDate = e => {\n    setStartDateInput(e.target.value);\n  }\n\n  const updateEndDate = e => {\n    setEndDateInput(e.target.value);\n  }\n\n  const clearInput = () => {\n    setTopicInput('');\n    setLimitInput('');\n    setStartDateInput('');\n    setEndDateInput('');\n  }\n\n  const isValidInput = () => {\n    if (!topicInput.trim()) {\n      alert(\"Please enter a topic\");\n      return false;\n    }\n\n    if (!limitInput.trim() || isNaN(limitInput.trim()) || parseInt(limitInput.trim(), 10) <= 0) {\n      alert(\"Please enter a valid limit for the number of results (MAX \" + MAX_RESULT_LIMIT + \")\");\n      return false;\n    }\n\n    if (startDateInput.trim() || endDateInput.trim()) {\n      if (!endDateInput.trim()) {\n        alert(\"Please enter an end date range\");\n        return false;\n      } else if (!startDateInput.trim()) {\n        alert(\"Please enter a start date range\");\n        return false;\n      } else if (new Date(startDateInput.trim()) == 'Invalid Date') {\n        alert(\"Please enter a valid start date (Ex: 1/01/2019)\");\n        return false;\n      } else if (new Date(endDateInput.trim()) == 'Invalid Date') {\n        alert(\"Please enter a valid end date (Ex: 5/01/2020)\");\n        return false;\n      } else if (new Date(startDateInput.trim()).getTime() >= new Date(endDateInput.trim()).getTime()) {\n        alert(\"Make sure the start date range is earlier than the end date range\");\n        return false;\n      }\n    }\n\n    return true;\n  }\n\n  const submitForm = e => {\n    e.preventDefault();\n    if (isValidInput()) {\n      setShowResults(false);\n      setQuery({\n        topic: topicInput.trim(),\n        limit: Math.min(MAX_RESULT_LIMIT, parseInt(limitInput.trim(), 10)),\n        startDate: startDateInput.trim(),\n        endDate: endDateInput.trim()\n      });\n    }\n    clearInput();\n  }\n\n  return (\n    <div className='App'>\n      <Helmet>\n        <title>{\"arXived\"}</title>\n      </Helmet>\n\n      <header className=\"App-header\">\n        <h1 className=\"App-title\">arXived</h1>\n      </header>\n\n      <form onSubmit={submitForm} className=\"input-form\" >\n        <input className=\"topic-search-bar\" type=\"text\" placeholder=\"Enter a topic or author of interest\"\n          value={topicInput} onChange={updateTopic} />\n        <input className=\"limit-input-bar\" type=\"text\" placeholder={\"Result Limit (MAX \" + MAX_RESULT_LIMIT + \")\"}\n          value={limitInput} onChange={updateLimit} />\n        <input className=\"date-input-bar\" type=\"text\" placeholder=\"1/01/2020 (Optional Start Date)\"\n          value={startDateInput} onChange={updateStartDate} />\n        <input className=\"date-input-bar\" type=\"text\" placeholder=\"5/01/2020 (Optional End Date)\"\n          value={endDateInput} onChange={updateEndDate} />\n        <button className=\"submit-button\" type=\"submit\">\n          Scrape arXiv\n        </button>\n      </form>\n\n      {/* Conditionally render views based on whether or not the results have been fully scraped */}\n      <div className='entries'>\n        {showResults ?\n          <div style={{ 'textAlign': 'center' }}>\n            <h2>Top matches for \"{query.topic}\"</h2>\n            <p><CSVLink data={entries} filename=\"arxiv_data.csv\" target=\"_blank\">Download as CSV</CSVLink> for all {entries.length} results.</p>\n          </div>\n          :\n          <div style={{ 'textAlign': 'center' }}>\n            <h2>Scraping information...</h2>\n            <p>If you chose a date range in the distant past, this may take several minutes...</p>\n            <p>Try recent date ranges or omitting the range altogether for faster, more reliable queries.</p>\n            <br />\n            <ClipLoader size={100} color={\"#123abc\"} />\n            <br />\n          </div>}\n        \n        {/* Show only a subset of the full data on the web page for performnance purposes */}\n        {showResults ? entries.slice(0, Math.min(MAX_TOP_MATCHES, entries.length)).map((data, i) => (\n          <Entry key={i} data={data} />\n        )) : null}\n\n      </div>\n    </div>\n  );\n};\n\nexport default App;","// This optional code is used to register a service worker.\n// register() is not called by default.\n\n// This lets the app load faster on subsequent visits in production, and gives\n// it offline capabilities. However, it also means that developers (and users)\n// will only see deployed updates on subsequent visits to a page, after all the\n// existing tabs open on the page have been closed, since previously cached\n// resources are updated in the background.\n\n// To learn more about the benefits of this model and instructions on how to\n// opt-in, read https://bit.ly/CRA-PWA\n\nconst isLocalhost = Boolean(\n  window.location.hostname === 'localhost' ||\n    // [::1] is the IPv6 localhost address.\n    window.location.hostname === '[::1]' ||\n    // 127.0.0.0/8 are considered localhost for IPv4.\n    window.location.hostname.match(\n      /^127(?:\\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/\n    )\n);\n\nexport function register(config) {\n  if (process.env.NODE_ENV === 'production' && 'serviceWorker' in navigator) {\n    // The URL constructor is available in all browsers that support SW.\n    const publicUrl = new URL(process.env.PUBLIC_URL, window.location.href);\n    if (publicUrl.origin !== window.location.origin) {\n      // Our service worker won't work if PUBLIC_URL is on a different origin\n      // from what our page is served on. This might happen if a CDN is used to\n      // serve assets; see https://github.com/facebook/create-react-app/issues/2374\n      return;\n    }\n\n    window.addEventListener('load', () => {\n      const swUrl = `${process.env.PUBLIC_URL}/service-worker.js`;\n\n      if (isLocalhost) {\n        // This is running on localhost. Let's check if a service worker still exists or not.\n        checkValidServiceWorker(swUrl, config);\n\n        // Add some additional logging to localhost, pointing developers to the\n        // service worker/PWA documentation.\n        navigator.serviceWorker.ready.then(() => {\n          console.log(\n            'This web app is being served cache-first by a service ' +\n              'worker. To learn more, visit https://bit.ly/CRA-PWA'\n          );\n        });\n      } else {\n        // Is not localhost. Just register service worker\n        registerValidSW(swUrl, config);\n      }\n    });\n  }\n}\n\nfunction registerValidSW(swUrl, config) {\n  navigator.serviceWorker\n    .register(swUrl)\n    .then(registration => {\n      registration.onupdatefound = () => {\n        const installingWorker = registration.installing;\n        if (installingWorker == null) {\n          return;\n        }\n        installingWorker.onstatechange = () => {\n          if (installingWorker.state === 'installed') {\n            if (navigator.serviceWorker.controller) {\n              // At this point, the updated precached content has been fetched,\n              // but the previous service worker will still serve the older\n              // content until all client tabs are closed.\n              console.log(\n                'New content is available and will be used when all ' +\n                  'tabs for this page are closed. See https://bit.ly/CRA-PWA.'\n              );\n\n              // Execute callback\n              if (config && config.onUpdate) {\n                config.onUpdate(registration);\n              }\n            } else {\n              // At this point, everything has been precached.\n              // It's the perfect time to display a\n              // \"Content is cached for offline use.\" message.\n              console.log('Content is cached for offline use.');\n\n              // Execute callback\n              if (config && config.onSuccess) {\n                config.onSuccess(registration);\n              }\n            }\n          }\n        };\n      };\n    })\n    .catch(error => {\n      console.error('Error during service worker registration:', error);\n    });\n}\n\nfunction checkValidServiceWorker(swUrl, config) {\n  // Check if the service worker can be found. If it can't reload the page.\n  fetch(swUrl, {\n    headers: { 'Service-Worker': 'script' },\n  })\n    .then(response => {\n      // Ensure service worker exists, and that we really are getting a JS file.\n      const contentType = response.headers.get('content-type');\n      if (\n        response.status === 404 ||\n        (contentType != null && contentType.indexOf('javascript') === -1)\n      ) {\n        // No service worker found. Probably a different app. Reload the page.\n        navigator.serviceWorker.ready.then(registration => {\n          registration.unregister().then(() => {\n            window.location.reload();\n          });\n        });\n      } else {\n        // Service worker found. Proceed as normal.\n        registerValidSW(swUrl, config);\n      }\n    })\n    .catch(() => {\n      console.log(\n        'No internet connection found. App is running in offline mode.'\n      );\n    });\n}\n\nexport function unregister() {\n  if ('serviceWorker' in navigator) {\n    navigator.serviceWorker.ready\n      .then(registration => {\n        registration.unregister();\n      })\n      .catch(error => {\n        console.error(error.message);\n      });\n  }\n}\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport * as serviceWorker from './serviceWorker';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want your app to work offline and load faster, you can change\n// unregister() to register() below. Note this comes with some pitfalls.\n// Learn more about service workers: https://bit.ly/CRA-PWA\nserviceWorker.unregister();\n"],"sourceRoot":""}